{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/yihuiwang/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk; nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "#Gensim\n",
    "import gensim\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "\n",
    "#Spacy for lemmatization\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('pub_abstract.csv')\n",
    "df = df[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df['abstract'].astype(str).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_to_words(sentences):\n",
    "    for sentence in sentences:\n",
    "        yield(gensim.utils.simple_preprocess(str(sentence),deacc=True))   #deacc = True...remove punctuations\n",
    "        \n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['within', 'the', 'field', 'of', 'information', 'systems', 'is', 'user', 'involvement', 'generally', 'refers', 'to', 'participation', 'in', 'the', 'systems', 'development', 'process', 'by', 'potential', 'users', 'or', 'their', 'representatives', 'and', 'is', 'measured', 'as', 'set', 'of', 'behaviors', 'or', 'activities', 'that', 'such', 'individuals', 'perform', 'this', 'article', 'argues', 'for', 'separation', 'of', 'the', 'constructs', 'of', 'user', 'participation', 'set', 'of', 'behaviors', 'or', 'activities', 'performed', 'by', 'users', 'in', 'the', 'system', 'development', 'process', 'and', 'user', 'involvement', 'subjective', 'psychological', 'state', 'reflecting', 'the', 'importance', 'and', 'personal', 'relevance', 'of', 'system', 'to', 'the', 'user', 'such', 'distinction', 'is', 'not', 'only', 'more', 'consistent', 'with', 'of', 'involvement', 'found', 'in', 'other', 'disciplines', 'but', 'it', 'also', 'leads', 'to', 'number', 'of', 'new', 'and', 'interesting', 'hypotheses', 'these', 'hypotheses', 'promise', 'richer', 'theoretical', 'network', 'that', 'describes', 'the', 'role', 'and', 'importance', 'of', 'participation', 'and', 'involvement', 'in', 'the', 'implementation', 'process']]\n"
     ]
    }
   ],
   "source": [
    "print(data_words[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['within', 'the', 'field', 'of', 'information', 'systems', 'is', 'user_involvement', 'generally', 'refers', 'to', 'participation', 'in', 'the', 'systems', 'development', 'process', 'by', 'potential', 'users', 'or', 'their', 'representatives', 'and', 'is', 'measured', 'as', 'set', 'of', 'behaviors', 'or', 'activities', 'that', 'such', 'individuals', 'perform', 'this', 'article', 'argues', 'for', 'separation', 'of', 'the', 'constructs', 'of', 'user', 'participation', 'set', 'of', 'behaviors', 'or', 'activities', 'performed', 'by', 'users', 'in', 'the', 'system', 'development', 'process', 'and', 'user_involvement', 'subjective', 'psychological', 'state', 'reflecting', 'the', 'importance', 'and', 'personal', 'relevance', 'of', 'system', 'to', 'the', 'user', 'such', 'distinction', 'is', 'not', 'only', 'more', 'consistent', 'with', 'of', 'involvement', 'found', 'in', 'other', 'disciplines', 'but', 'it', 'also', 'leads', 'to', 'number', 'of', 'new', 'and', 'interesting', 'hypotheses', 'these', 'hypotheses', 'promise', 'richer', 'theoretical', 'network', 'that', 'describes', 'the', 'role', 'and', 'importance', 'of', 'participation', 'and', 'involvement', 'in', 'the', 'implementation', 'process']\n"
     ]
    }
   ],
   "source": [
    "#Creat Bigram\n",
    "bigram = gensim.models.Phrases(data_words, min_count= 5, threshold= 100)   #higher threshold fewer phrases\n",
    "\n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "\n",
    "print(bigram_mod[data_words[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(texts):\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_bigrams(texts):\n",
    "    return [bigram_mod[doc] for doc in texts]\n",
    "\n",
    "def lemmatization(texts, allowed_postags = ['NOUN','ADJ','VERB','ADV']):\n",
    "    \"\"\"https://spacy.io/api./annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['field', 'information', 'system', 'user_involvement', 'generally', 'refer', 'participation', 'system', 'development', 'process', 'potential', 'user', 'representative', 'measure', 'set', 'behavior', 'activity', 'individual', 'perform', 'article', 'argue', 'separation', 'construct', 'user', 'participation', 'set', 'behavior', 'activity', 'perform', 'user', 'system', 'development', 'process', 'user_involvement', 'subjective', 'psychological', 'state', 'reflect', 'importance', 'personal', 'relevance', 'system', 'user', 'distinction', 'consistent', 'involvement', 'find', 'discipline', 'also', 'lead', 'number', 'new', 'interesting', 'hypothesis', 'hypothesis', 'promise', 'rich', 'theoretical', 'network', 'describe', 'role', 'importance', 'participation', 'involvement', 'implementation', 'process']]\n"
     ]
    }
   ],
   "source": [
    "data_words_nostops = remove_stopwords(data_words)\n",
    "\n",
    "#For Bigrams\n",
    "data_words_bigrams = make_bigrams(data_words_nostops)\n",
    "\n",
    "#initialize spacy 'en' model\n",
    "#python3 -m spacy download en\n",
    "\n",
    "nlp = spacy.load('en', disable =['parser','ner'] )\n",
    "\n",
    "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN','ADJ','VERB','ADV'])\n",
    "\n",
    "print(data_lemmatized[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(0, 2), (1, 1), (2, 1), (3, 1), (4, 2), (5, 1), (6, 1), (7, 1), (8, 2), (9, 1), (10, 1), (11, 1), (12, 1), (13, 1), (14, 2), (15, 1), (16, 2), (17, 1), (18, 1), (19, 1), (20, 2), (21, 1), (22, 1), (23, 1), (24, 1), (25, 1), (26, 3), (27, 2), (28, 1), (29, 1), (30, 3), (31, 1), (32, 1), (33, 1), (34, 1), (35, 1), (36, 1), (37, 1), (38, 1), (39, 1), (40, 2), (41, 1), (42, 1), (43, 4), (44, 1), (45, 4), (46, 2)]]\n"
     ]
    }
   ],
   "source": [
    "#Creat Disctionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "#Creat Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "#Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "#View \n",
    "print(corpus[:1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'activity'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word in given id\n",
    "id2word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihuiwang/Envs/ivy/lib/python3.7/site-packages/ipykernel_launcher.py:5: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[(0,\n",
      "  '0.020*\"service\" + 0.015*\"web\" + 0.014*\"propose\" + 0.012*\"emr\" + '\n",
      "  '0.010*\"application\" + 0.009*\"use\" + 0.009*\"mobile\" + 0.009*\"signature\" + '\n",
      "  '0.009*\"quality\" + 0.008*\"base\"'),\n",
      " (1,\n",
      "  '0.009*\"knowledge\" + 0.007*\"disease\" + 0.007*\"use\" + 0.007*\"bdl\" + '\n",
      "  '0.007*\"intention\" + 0.007*\"technology\" + 0.007*\"problem\" + 0.006*\"research\" '\n",
      "  '+ 0.006*\"application\" + 0.006*\"useful\"'),\n",
      " (2,\n",
      "  '0.023*\"research\" + 0.014*\"system\" + 0.013*\"use\" + 0.010*\"paper\" + '\n",
      "  '0.010*\"service\" + 0.010*\"literature\" + 0.008*\"review\" + 0.008*\"innovation\" '\n",
      "  '+ 0.008*\"technology\" + 0.008*\"analysis\"'),\n",
      " (3,\n",
      "  '0.021*\"knowledge\" + 0.014*\"key\" + 0.012*\"domain\" + 0.011*\"management\" + '\n",
      "  '0.011*\"developer\" + 0.009*\"community\" + 0.008*\"organizational\" + '\n",
      "  '0.008*\"logical\" + 0.008*\"happiness\" + 0.007*\"social\"'),\n",
      " (4,\n",
      "  '0.013*\"knowledge\" + 0.013*\"performance\" + 0.013*\"sme\" + 0.012*\"transfer\" + '\n",
      "  '0.011*\"route\" + 0.009*\"practice\" + 0.008*\"cognitive\" + 0.008*\"model\" + '\n",
      "  '0.007*\"study\" + 0.007*\"find\"'),\n",
      " (5,\n",
      "  '0.012*\"system\" + 0.009*\"knowledge\" + 0.009*\"design\" + 0.009*\"information\" + '\n",
      "  '0.008*\"study\" + 0.008*\"online\" + 0.007*\"develop\" + 0.007*\"paper\" + '\n",
      "  '0.006*\"software\" + 0.006*\"result\"'),\n",
      " (6,\n",
      "  '0.017*\"group\" + 0.012*\"process\" + 0.011*\"study\" + 0.010*\"model\" + '\n",
      "  '0.009*\"use\" + 0.009*\"adoption\" + 0.008*\"business\" + 0.008*\"technology\" + '\n",
      "  '0.007*\"high\" + 0.007*\"work\"'),\n",
      " (7,\n",
      "  '0.014*\"medium\" + 0.013*\"interaction\" + 0.009*\"resource\" + 0.009*\"alignment\" '\n",
      "  '+ 0.009*\"learn\" + 0.009*\"performance\" + 0.008*\"base\" + 0.007*\"market\" + '\n",
      "  '0.007*\"spectrum\" + 0.007*\"level\"'),\n",
      " (8,\n",
      "  '0.021*\"system\" + 0.014*\"information\" + 0.013*\"model\" + 0.010*\"research\" + '\n",
      "  '0.009*\"use\" + 0.009*\"process\" + 0.009*\"datum\" + 0.008*\"development\" + '\n",
      "  '0.008*\"organization\" + 0.007*\"base\"'),\n",
      " (9,\n",
      "  '0.020*\"market\" + 0.014*\"information\" + 0.008*\"support\" + 0.008*\"security\" + '\n",
      "  '0.007*\"theory\" + 0.007*\"rfid\" + 0.007*\"use\" + 0.006*\"analysis\" + '\n",
      "  '0.006*\"alone\" + 0.006*\"china\"')]\n",
      "\n",
      "Perplexity: -7.627948521562831\n",
      "\n",
      "Coherence Score: 0.34390132664702433\n",
      "20\n",
      "[(0,\n",
      "  '0.041*\"scheme\" + 0.018*\"functionality\" + 0.017*\"security\" + 0.013*\"service\" '\n",
      "  '+ 0.012*\"factor\" + 0.010*\"requirement\" + 0.010*\"mobile\" + 0.010*\"current\" + '\n",
      "  '0.010*\"generate\" + 0.009*\"provide\"'),\n",
      " (1,\n",
      "  '0.030*\"system\" + 0.026*\"application\" + 0.022*\"tool\" + 0.022*\"dynamic\" + '\n",
      "  '0.020*\"decision\" + 0.018*\"problem\" + 0.016*\"propose\" + 0.013*\"element\" + '\n",
      "  '0.013*\"time\" + 0.012*\"development\"'),\n",
      " (2,\n",
      "  '0.025*\"network\" + 0.018*\"describe\" + 0.015*\"strength\" + 0.015*\"association\" '\n",
      "  '+ 0.013*\"user_involvement\" + 0.013*\"political\" + 0.011*\"base\" + '\n",
      "  '0.011*\"simulation\" + 0.010*\"signal\" + 0.010*\"organizational\"'),\n",
      " (3,\n",
      "  '0.039*\"website\" + 0.036*\"community\" + 0.019*\"task\" + 0.018*\"key\" + '\n",
      "  '0.018*\"characteristic\" + 0.014*\"logical\" + 0.012*\"feature\" + 0.011*\"paper\" '\n",
      "  '+ 0.010*\"grand\" + 0.010*\"publication\"'),\n",
      " (4,\n",
      "  '0.052*\"model\" + 0.030*\"solution\" + 0.022*\"overall\" + 0.019*\"simulation\" + '\n",
      "  '0.018*\"client\" + 0.013*\"servqual\" + 0.013*\"input\" + 0.012*\"point\" + '\n",
      "  '0.011*\"sna\" + 0.011*\"discrete\"'),\n",
      " (5,\n",
      "  '0.013*\"online\" + 0.013*\"software\" + 0.010*\"platform\" + 0.010*\"future\" + '\n",
      "  '0.010*\"study\" + 0.009*\"associate\" + 0.009*\"quality\" + 0.009*\"result\" + '\n",
      "  '0.009*\"level\" + 0.009*\"search\"'),\n",
      " (6,\n",
      "  '0.015*\"model\" + 0.014*\"adoption\" + 0.011*\"commerce\" + 0.011*\"use\" + '\n",
      "  '0.011*\"time\" + 0.010*\"information\" + 0.010*\"prediction\" + 0.009*\"study\" + '\n",
      "  '0.009*\"technology\" + 0.009*\"research\"'),\n",
      " (7,\n",
      "  '0.041*\"group\" + 0.033*\"medium\" + 0.024*\"interaction\" + 0.018*\"learn\" + '\n",
      "  '0.013*\"level\" + 0.012*\"user\" + 0.011*\"virtual\" + 0.011*\"cell\" + '\n",
      "  '0.009*\"target\" + 0.009*\"decrease\"'),\n",
      " (8,\n",
      "  '0.019*\"individual\" + 0.018*\"information\" + 0.013*\"design\" + 0.012*\"risk\" + '\n",
      "  '0.012*\"organization\" + 0.011*\"research\" + 0.010*\"survey\" + '\n",
      "  '0.010*\"organizational\" + 0.009*\"base\" + 0.009*\"result\"'),\n",
      " (9,\n",
      "  '0.053*\"market\" + 0.019*\"information\" + 0.017*\"support\" + 0.016*\"product\" + '\n",
      "  '0.014*\"use\" + 0.013*\"rfid\" + 0.012*\"consumption\" + 0.011*\"base\" + '\n",
      "  '0.011*\"price\" + 0.011*\"infrastructure\"'),\n",
      " (10,\n",
      "  '0.029*\"practice\" + 0.028*\"sme\" + 0.018*\"group\" + 0.017*\"small\" + '\n",
      "  '0.016*\"resource\" + 0.015*\"south\" + 0.014*\"allocation\" + 0.014*\"algorithm\" + '\n",
      "  '0.013*\"innovation\" + 0.012*\"solve\"'),\n",
      " (11,\n",
      "  '0.024*\"speech\" + 0.022*\"host\" + 0.020*\"opn\" + 0.020*\"fgf\" + 0.018*\"normal\" '\n",
      "  '+ 0.018*\"expression\" + 0.014*\"nsclc\" + 0.013*\"would\" + 0.011*\"device\" + '\n",
      "  '0.010*\"lens\"'),\n",
      " (12,\n",
      "  '0.037*\"system\" + 0.020*\"research\" + 0.013*\"support\" + 0.011*\"provide\" + '\n",
      "  '0.011*\"development\" + 0.011*\"review\" + 0.010*\"method\" + 0.010*\"paper\" + '\n",
      "  '0.010*\"base\" + 0.010*\"information\"'),\n",
      " (13,\n",
      "  '0.019*\"advertising\" + 0.015*\"sequence\" + 0.015*\"deal\" + '\n",
      "  '0.014*\"administrative\" + 0.014*\"capability\" + 0.013*\"quality\" + '\n",
      "  '0.012*\"video\" + 0.011*\"offer\" + 0.010*\"ticketmonster\" + 0.009*\"compete\"'),\n",
      " (14,\n",
      "  '0.036*\"datum\" + 0.036*\"performance\" + 0.017*\"standard\" + 0.017*\"firm\" + '\n",
      "  '0.016*\"alignment\" + 0.015*\"disease\" + 0.014*\"strategy\" + 0.014*\"chain\" + '\n",
      "  '0.013*\"operational\" + 0.011*\"competitive_advantage\"'),\n",
      " (15,\n",
      "  '0.028*\"use\" + 0.024*\"system\" + 0.020*\"model\" + 0.019*\"service\" + '\n",
      "  '0.015*\"information\" + 0.015*\"technology\" + 0.015*\"present\" + 0.014*\"paper\" '\n",
      "  '+ 0.012*\"analysis\" + 0.012*\"project\"'),\n",
      " (16,\n",
      "  '0.024*\"user\" + 0.017*\"use\" + 0.016*\"technology\" + 0.014*\"propose\" + '\n",
      "  '0.013*\"intention\" + 0.013*\"web\" + 0.012*\"self\" + 0.012*\"economic\" + '\n",
      "  '0.012*\"public\" + 0.012*\"study\"'),\n",
      " (17,\n",
      "  '0.049*\"innovation\" + 0.031*\"student\" + 0.028*\"china\" + 0.019*\"course\" + '\n",
      "  '0.017*\"manufacturing\" + 0.015*\"network\" + 0.013*\"output\" + '\n",
      "  '0.011*\"production\" + 0.010*\"structure\" + 0.010*\"respond\"'),\n",
      " (18,\n",
      "  '0.033*\"attribution\" + 0.017*\"causal\" + 0.014*\"researcher\" + '\n",
      "  '0.010*\"colleague\" + 0.010*\"reliability\" + 0.009*\"scale\" + 0.008*\"theory\" + '\n",
      "  '0.004*\"sometimes\" + 0.004*\"weiner\" + 0.004*\"multimethod\"'),\n",
      " (19,\n",
      "  '0.043*\"knowledge\" + 0.023*\"process\" + 0.019*\"management\" + '\n",
      "  '0.015*\"organizational\" + 0.013*\"framework\" + 0.013*\"organization\" + '\n",
      "  '0.013*\"source\" + 0.012*\"research\" + 0.012*\"practice\" + '\n",
      "  '0.012*\"collaboration\"')]\n",
      "\n",
      "Perplexity: -9.463622171502278\n",
      "\n",
      "Coherence Score: 0.34224480206676916\n",
      "30\n",
      "[(18,\n",
      "  '0.000*\"group\" + 0.000*\"commerce\" + 0.000*\"work\" + 0.000*\"attribution\" + '\n",
      "  '0.000*\"technology\" + 0.000*\"gastrin\" + 0.000*\"animal\" + 0.000*\"theory\" + '\n",
      "  '0.000*\"decision\" + 0.000*\"electronic\"'),\n",
      " (3,\n",
      "  '0.047*\"logical\" + 0.040*\"key\" + 0.025*\"processing\" + 0.018*\"cost\" + '\n",
      "  '0.017*\"management\" + 0.016*\"tree\" + 0.012*\"problem\" + 0.011*\"base\" + '\n",
      "  '0.011*\"datum\" + 0.010*\"multicast\"'),\n",
      " (4,\n",
      "  '0.036*\"political\" + 0.027*\"association\" + 0.026*\"affiliation\" + '\n",
      "  '0.023*\"similarity\" + 0.017*\"science\" + 0.013*\"american\" + 0.013*\"timely\" + '\n",
      "  '0.013*\"spur\" + 0.013*\"severe\" + 0.012*\"group\"'),\n",
      " (0,\n",
      "  '0.046*\"administrative\" + 0.022*\"tanzania\" + 0.020*\"significant\" + '\n",
      "  '0.014*\"exploit\" + 0.013*\"various\" + 0.013*\"process\" + 0.012*\"government\" + '\n",
      "  '0.009*\"develop\" + 0.009*\"scale\" + 0.008*\"exchange\"'),\n",
      " (27,\n",
      "  '0.053*\"provider\" + 0.021*\"service\" + 0.020*\"broadband\" + 0.018*\"capacity\" + '\n",
      "  '0.016*\"high\" + 0.015*\"consumer\" + 0.015*\"run\" + 0.014*\"content\" + '\n",
      "  '0.014*\"inform\" + 0.013*\"surplus\"'),\n",
      " (11,\n",
      "  '0.039*\"inter_organizational\" + 0.036*\"speech\" + 0.034*\"host\" + '\n",
      "  '0.022*\"happiness\" + 0.021*\"could\" + 0.016*\"unhappiness\" + 0.015*\"owner\" + '\n",
      "  '0.015*\"system\" + 0.012*\"meaningful\" + 0.012*\"author\"'),\n",
      " (13,\n",
      "  '0.030*\"information\" + 0.026*\"adapt\" + 0.023*\"infrastructure\" + '\n",
      "  '0.017*\"database\" + 0.013*\"recognition\" + 0.012*\"new\" + 0.012*\"smart\" + '\n",
      "  '0.012*\"feature\" + 0.011*\"various\" + 0.009*\"novel\"'),\n",
      " (21,\n",
      "  '0.027*\"interaction\" + 0.020*\"start\" + 0.017*\"manager\" + 0.017*\"security\" + '\n",
      "  '0.014*\"privacy\" + 0.013*\"method\" + 0.012*\"proposal\" + 0.012*\"effective\" + '\n",
      "  '0.012*\"resource\" + 0.012*\"initial\"'),\n",
      " (14,\n",
      "  '0.042*\"sme\" + 0.023*\"cell\" + 0.023*\"practice\" + 0.022*\"south\" + '\n",
      "  '0.019*\"decrease\" + 0.017*\"effect\" + 0.016*\"meet\" + 0.014*\"significant\" + '\n",
      "  '0.013*\"overall\" + 0.013*\"level\"'),\n",
      " (22,\n",
      "  '0.076*\"group\" + 0.027*\"student\" + 0.026*\"individual\" + 0.016*\"security\" + '\n",
      "  '0.015*\"control\" + 0.013*\"animal\" + 0.013*\"course\" + 0.011*\"lens\" + '\n",
      "  '0.011*\"gastrin\" + 0.010*\"element\"'),\n",
      " (9,\n",
      "  '0.050*\"market\" + 0.020*\"performance\" + 0.018*\"theory\" + 0.018*\"support\" + '\n",
      "  '0.015*\"rfid\" + 0.015*\"product\" + 0.014*\"use\" + 0.013*\"china\" + '\n",
      "  '0.013*\"alone\" + 0.013*\"may\"'),\n",
      " (10,\n",
      "  '0.018*\"need\" + 0.018*\"practice\" + 0.016*\"process\" + 0.016*\"system\" + '\n",
      "  '0.016*\"resource\" + 0.014*\"solution\" + 0.014*\"user\" + 0.014*\"generation\" + '\n",
      "  '0.013*\"new\" + 0.013*\"change\"'),\n",
      " (24,\n",
      "  '0.032*\"datum\" + 0.018*\"risk\" + 0.017*\"information\" + 0.016*\"level\" + '\n",
      "  '0.014*\"search\" + 0.014*\"online\" + 0.013*\"associate\" + 0.012*\"purchase\" + '\n",
      "  '0.011*\"use\" + 0.011*\"behavior\"'),\n",
      " (23,\n",
      "  '0.032*\"knowledge\" + 0.028*\"management\" + 0.027*\"datum\" + 0.021*\"price\" + '\n",
      "  '0.020*\"process\" + 0.018*\"individual\" + 0.017*\"auction\" + '\n",
      "  '0.017*\"organization\" + 0.014*\"framework\" + 0.013*\"lead\"'),\n",
      " (19,\n",
      "  '0.075*\"knowledge\" + 0.035*\"organizational\" + 0.029*\"source\" + '\n",
      "  '0.025*\"transfer\" + 0.018*\"process\" + 0.017*\"standard\" + 0.016*\"domain\" + '\n",
      "  '0.014*\"cognitive\" + 0.014*\"environment\" + 0.013*\"organization\"'),\n",
      " (28,\n",
      "  '0.018*\"collaboration\" + 0.017*\"project\" + 0.016*\"use\" + 0.012*\"difference\" '\n",
      "  '+ 0.012*\"development\" + 0.012*\"method\" + 0.012*\"challenge\" + '\n",
      "  '0.011*\"technology\" + 0.010*\"paper\" + 0.010*\"algorithm\"'),\n",
      " (20,\n",
      "  '0.021*\"research\" + 0.018*\"factor\" + 0.017*\"adoption\" + 0.016*\"development\" '\n",
      "  '+ 0.016*\"information\" + 0.012*\"theory\" + 0.012*\"problem\" + '\n",
      "  '0.012*\"prediction\" + 0.010*\"study\" + 0.010*\"software\"'),\n",
      " (8,\n",
      "  '0.032*\"community\" + 0.022*\"survey\" + 0.018*\"study\" + 0.016*\"base\" + '\n",
      "  '0.016*\"research\" + 0.014*\"contribution\" + 0.014*\"information\" + '\n",
      "  '0.013*\"organizational\" + 0.012*\"government\" + 0.012*\"software_piracy\"'),\n",
      " (12,\n",
      "  '0.032*\"system\" + 0.032*\"research\" + 0.025*\"method\" + 0.020*\"review\" + '\n",
      "  '0.016*\"area\" + 0.016*\"literature\" + 0.014*\"use\" + 0.014*\"provide\" + '\n",
      "  '0.012*\"tool\" + 0.012*\"develop\"'),\n",
      " (25,\n",
      "  '0.025*\"model\" + 0.023*\"use\" + 0.019*\"support\" + 0.014*\"provide\" + '\n",
      "  '0.014*\"technology\" + 0.011*\"process\" + 0.011*\"business\" + '\n",
      "  '0.011*\"management\" + 0.011*\"study\" + 0.011*\"information\"')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Perplexity: -10.47116061177928\n",
      "\n",
      "Coherence Score: 0.34016903319100494\n",
      "14.492186999999998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yihuiwang/Envs/ivy/lib/python3.7/site-packages/ipykernel_launcher.py:26: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n"
     ]
    }
   ],
   "source": [
    "# Build LDA model for different number of topics\n",
    "\n",
    "import time\n",
    "start = time.clock()\n",
    "num_topics_range = list(range(10,60,10))\n",
    "\n",
    "for i in num_topics_range:\n",
    "    num_topics = i\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                                                   id2word = id2word,\n",
    "                                                                   num_topics= i,\n",
    "                                                                   random_state=100,\n",
    "                                                                   update_every=1,\n",
    "                                                                   chunksize=100,\n",
    "                                                                   passes=10,\n",
    "                                                                   alpha='auto',\n",
    "                                                                   per_word_topics=True)\n",
    "    print(i)\n",
    "    pprint(lda_model.print_topics())\n",
    "    #Compute Perplexity\n",
    "    print('\\nPerplexity:', lda_model.log_perplexity(corpus))    #a measure of how good the model is, lower the better\n",
    "    \n",
    "    #Compute Coherence Score\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    coherence_lda = coherence_model_lda.get_coherence()\n",
    "    print('\\nCoherence Score:', coherence_lda)\n",
    "\n",
    "end = (time.clock() - start)\n",
    "print(end)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'import time\n",
    "start = time.clock()\n",
    "Build LDA model\n",
    "'lda_model = gensim.models.ldamodel.LdaModel(corpus = corpus,\n",
    "                                                                   id2word = id2word,\n",
    "                                                                   num_topics= 15,\n",
    "                                                                   random_state=100,\n",
    "                                                                   update_every=1,\n",
    "                                                                   chunksize=100,\n",
    "                                                                   passes=10,\n",
    "                                                                   alpha='auto',\n",
    "                                                                   per_word_topics=True)\n",
    "\n",
    "elapsed = (time.clock() - start)\n",
    "print(elapsed)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
